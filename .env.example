# LLM Provider Configuration
# Options: "ollama" (local) or "openai" (remote)
LLM_PROVIDER=ollama

# OpenAI Configuration (only needed if LLM_PROVIDER=openai)
OPENAI_API_KEY=

# Ollama Configuration (only needed if LLM_PROVIDER=ollama)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Embedding model for Ollama
EMBEDDING_MODEL=nomic-embed-text

# Development mode (enables debug logging, uses separate dev database)
DEV_MODE=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

USE_GENERIC_PARSER=true